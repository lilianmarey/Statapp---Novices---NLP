{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:02:18: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO - 21:02:18: built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "# Importation des modules\n",
    "\n",
    "import pandas as pd\n",
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#Affichage de toutes les colonnes\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/data_cleaned_NLP.csv', sep = ',', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0[['Réplique', 'Groupe', 'tokenized_replique']].copy()\n",
    "\n",
    "df2 = df1[['Groupe', 'tokenized_replique']].copy()\n",
    "\n",
    "df_novice = df2[df2['Groupe'] == 'Novice'].copy()\n",
    "df_exp = df2[df2['Groupe'] == 'Exp'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novice = df_novice.dropna()\n",
    "\n",
    "df_exp = df_exp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_novice = [row.split() for row in df_novice['tokenized_replique']]\n",
    "\n",
    "sent_exp = [row.split() for row in df_exp['tokenized_replique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:52:11: collecting all words and their counts\n",
      "INFO - 20:52:11: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 20:52:12: PROGRESS: at sentence #20000, processed 544399 words and 367942 word types\n",
      "INFO - 20:52:14: PROGRESS: at sentence #40000, processed 1061844 words and 645502 word types\n",
      "INFO - 20:52:14: collected 773338 word types from a corpus of 1326670 words (unigram + bigrams) and 50191 sentences\n",
      "INFO - 20:52:14: using 773338 counts as vocab in Phrases<0 vocab, min_count=3, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 20:52:14: collecting all words and their counts\n",
      "INFO - 20:52:14: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 20:52:15: PROGRESS: at sentence #20000, processed 518787 words and 365570 word types\n",
      "INFO - 20:52:17: PROGRESS: at sentence #40000, processed 1056472 words and 658662 word types\n",
      "INFO - 20:52:18: PROGRESS: at sentence #60000, processed 1530225 words and 884119 word types\n",
      "INFO - 20:52:19: PROGRESS: at sentence #80000, processed 2021109 words and 1099782 word types\n",
      "INFO - 20:52:20: PROGRESS: at sentence #100000, processed 2530754 words and 1316508 word types\n",
      "INFO - 20:52:22: PROGRESS: at sentence #120000, processed 3091195 words and 1542161 word types\n",
      "INFO - 20:52:22: PROGRESS: at sentence #140000, processed 3492363 words and 1690307 word types\n",
      "INFO - 20:52:23: PROGRESS: at sentence #160000, processed 3827516 words and 1796729 word types\n",
      "INFO - 20:52:24: PROGRESS: at sentence #180000, processed 4116140 words and 1885664 word types\n",
      "INFO - 20:52:25: PROGRESS: at sentence #200000, processed 4652876 words and 2075194 word types\n",
      "INFO - 20:52:26: PROGRESS: at sentence #220000, processed 5173769 words and 2259183 word types\n",
      "INFO - 20:52:27: PROGRESS: at sentence #240000, processed 5648678 words and 2425973 word types\n",
      "INFO - 20:52:28: PROGRESS: at sentence #260000, processed 6139387 words and 2575760 word types\n",
      "INFO - 20:52:29: PROGRESS: at sentence #280000, processed 6634584 words and 2729208 word types\n",
      "INFO - 20:52:31: PROGRESS: at sentence #300000, processed 7164382 words and 2893910 word types\n",
      "INFO - 20:52:32: PROGRESS: at sentence #320000, processed 7711168 words and 3057317 word types\n",
      "INFO - 20:52:33: PROGRESS: at sentence #340000, processed 8221718 words and 3206295 word types\n",
      "INFO - 20:52:34: PROGRESS: at sentence #360000, processed 8672434 words and 3335018 word types\n",
      "INFO - 20:52:35: PROGRESS: at sentence #380000, processed 8861978 words and 3371134 word types\n",
      "INFO - 20:52:36: PROGRESS: at sentence #400000, processed 9333965 words and 3508565 word types\n",
      "INFO - 20:52:37: PROGRESS: at sentence #420000, processed 9789642 words and 3631848 word types\n",
      "INFO - 20:52:38: PROGRESS: at sentence #440000, processed 10262034 words and 3757534 word types\n",
      "INFO - 20:52:39: collected 3813404 word types from a corpus of 10479107 words (unigram + bigrams) and 448965 sentences\n",
      "INFO - 20:52:39: using 3813404 counts as vocab in Phrases<0 vocab, min_count=3, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases_novice = Phrases(sent_novice, min_count = 3, progress_per = 20000)\n",
    "\n",
    "phrases_exp = Phrases(sent_exp, min_count = 3, progress_per = 20000)\n",
    "\n",
    "\n",
    "# min_count : Ignore all words and bigrams with total collected count lower than this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:52:39: source_vocab length 773338\n",
      "INFO - 20:52:49: Phraser built with 16435 phrasegrams\n",
      "INFO - 20:52:49: source_vocab length 3813404\n",
      "INFO - 20:52:59: Phraser added 50000 phrasegrams\n",
      "INFO - 20:53:37: Phraser built with 73757 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram_novice = Phraser(phrases_novice)\n",
    "\n",
    "bigram_exp = Phraser(phrases_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_novice = bigram_novice[sent_novice]\n",
    "\n",
    "sentences_exp = bigram_exp[sent_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_novice = defaultdict(int)\n",
    "word_freq_exp = defaultdict(int)\n",
    "\n",
    "for sent in sentences_novice:\n",
    "    for i in sent:\n",
    "        word_freq_novice[i] += 1\n",
    "        \n",
    "for sent in sentences_exp:\n",
    "    for i in sent:\n",
    "        word_freq_exp[i] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:14:18: collecting all words and their counts\n",
      "INFO - 00:14:18: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:14:19: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:14:20: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:14:21: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:14:22: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:14:22: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:14:22: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:14:22: Loading a fresh vocabulary\n",
      "INFO - 00:14:25: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:14:25: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:14:25: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:14:25: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:14:25: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:14:25: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:14:25: resetting layer weights\n",
      "INFO - 00:14:32: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=1\n",
      "INFO - 00:14:33: EPOCH 1 - PROGRESS: at 8.09% examples, 67250 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:34: EPOCH 1 - PROGRESS: at 24.42% examples, 91970 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:35: EPOCH 1 - PROGRESS: at 41.41% examples, 102186 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:14:36: EPOCH 1 - PROGRESS: at 57.44% examples, 106523 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:37: EPOCH 1 - PROGRESS: at 74.28% examples, 107649 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:38: EPOCH 1 - PROGRESS: at 87.49% examples, 105399 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:14:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:14:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:14:39: EPOCH - 1 : training on 1099932 raw words (749232 effective words) took 7.1s, 104966 effective words/s\n",
      "INFO - 00:14:40: EPOCH 2 - PROGRESS: at 10.44% examples, 88935 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:41: EPOCH 2 - PROGRESS: at 21.74% examples, 84931 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:42: EPOCH 2 - PROGRESS: at 37.34% examples, 93849 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:14:43: EPOCH 2 - PROGRESS: at 49.26% examples, 90975 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:44: EPOCH 2 - PROGRESS: at 59.89% examples, 88638 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:45: EPOCH 2 - PROGRESS: at 75.18% examples, 91313 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:46: EPOCH 2 - PROGRESS: at 90.98% examples, 94187 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:14:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:14:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:14:47: EPOCH - 2 : training on 1099932 raw words (749796 effective words) took 7.8s, 96042 effective words/s\n",
      "INFO - 00:14:48: EPOCH 3 - PROGRESS: at 10.44% examples, 85425 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:49: EPOCH 3 - PROGRESS: at 29.08% examples, 106427 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:50: EPOCH 3 - PROGRESS: at 45.26% examples, 112792 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:51: EPOCH 3 - PROGRESS: at 63.54% examples, 116899 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:52: EPOCH 3 - PROGRESS: at 83.31% examples, 119240 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:14:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:14:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:14:53: EPOCH - 3 : training on 1099932 raw words (749338 effective words) took 6.1s, 121945 effective words/s\n",
      "INFO - 00:14:54: EPOCH 4 - PROGRESS: at 14.59% examples, 123619 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:14:55: EPOCH 4 - PROGRESS: at 33.28% examples, 126791 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:56: EPOCH 4 - PROGRESS: at 50.17% examples, 127229 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:57: EPOCH 4 - PROGRESS: at 67.56% examples, 127130 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:14:58: EPOCH 4 - PROGRESS: at 86.59% examples, 128017 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:14:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:14:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:14:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:14:59: EPOCH - 4 : training on 1099932 raw words (748841 effective words) took 6.0s, 125229 effective words/s\n",
      "INFO - 00:15:00: EPOCH 5 - PROGRESS: at 10.44% examples, 81182 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:01: EPOCH 5 - PROGRESS: at 22.50% examples, 82602 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:02: EPOCH 5 - PROGRESS: at 35.26% examples, 85557 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:03: EPOCH 5 - PROGRESS: at 46.07% examples, 85792 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:04: EPOCH 5 - PROGRESS: at 59.03% examples, 86774 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:05: EPOCH 5 - PROGRESS: at 70.25% examples, 85208 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:06: EPOCH 5 - PROGRESS: at 83.31% examples, 84807 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:07: EPOCH 5 - PROGRESS: at 95.64% examples, 85612 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:08: EPOCH - 5 : training on 1099932 raw words (749292 effective words) took 8.6s, 86860 effective words/s\n",
      "INFO - 00:15:08: training on a 5499660 raw words (3746499 effective words) took 35.8s, 104780 effective words/s\n",
      "INFO - 00:15:08: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:15:08: collecting all words and their counts\n",
      "INFO - 00:15:08: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:15:09: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:15:10: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:15:10: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:15:11: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:15:12: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:15:12: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:15:12: Loading a fresh vocabulary\n",
      "INFO - 00:15:12: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:15:12: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:15:12: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:15:12: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:15:12: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:15:12: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:15:12: resetting layer weights\n",
      "INFO - 00:15:19: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 00:15:20: EPOCH 1 - PROGRESS: at 12.88% examples, 105912 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:21: EPOCH 1 - PROGRESS: at 29.88% examples, 111792 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:22: EPOCH 1 - PROGRESS: at 45.26% examples, 114238 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:23: EPOCH 1 - PROGRESS: at 62.67% examples, 116570 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:15:24: EPOCH 1 - PROGRESS: at 80.86% examples, 116687 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:25: EPOCH 1 - PROGRESS: at 97.94% examples, 118390 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 00:15:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:26: EPOCH - 1 : training on 1099932 raw words (749440 effective words) took 6.3s, 119339 effective words/s\n",
      "INFO - 00:15:27: EPOCH 2 - PROGRESS: at 13.68% examples, 111637 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:15:28: EPOCH 2 - PROGRESS: at 30.72% examples, 116361 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:29: EPOCH 2 - PROGRESS: at 44.53% examples, 113176 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:30: EPOCH 2 - PROGRESS: at 59.03% examples, 110460 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:31: EPOCH 2 - PROGRESS: at 72.66% examples, 105978 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:32: EPOCH 2 - PROGRESS: at 87.49% examples, 106231 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:33: EPOCH - 2 : training on 1099932 raw words (749034 effective words) took 7.1s, 105986 effective words/s\n",
      "INFO - 00:15:34: EPOCH 3 - PROGRESS: at 11.29% examples, 94088 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:35: EPOCH 3 - PROGRESS: at 26.72% examples, 98146 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:36: EPOCH 3 - PROGRESS: at 42.19% examples, 105358 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:37: EPOCH 3 - PROGRESS: at 58.21% examples, 107794 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:38: EPOCH 3 - PROGRESS: at 75.18% examples, 110350 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:15:39: EPOCH 3 - PROGRESS: at 91.94% examples, 111866 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:39: EPOCH - 3 : training on 1099932 raw words (748655 effective words) took 6.6s, 113342 effective words/s\n",
      "INFO - 00:15:40: EPOCH 4 - PROGRESS: at 12.88% examples, 109720 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:15:41: EPOCH 4 - PROGRESS: at 30.72% examples, 118120 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:15:42: EPOCH 4 - PROGRESS: at 47.15% examples, 121241 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:15:43: EPOCH 4 - PROGRESS: at 63.54% examples, 119922 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:44: EPOCH 4 - PROGRESS: at 80.86% examples, 118430 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:45: EPOCH 4 - PROGRESS: at 97.79% examples, 119612 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:46: EPOCH - 4 : training on 1099932 raw words (749581 effective words) took 6.3s, 119887 effective words/s\n",
      "INFO - 00:15:47: EPOCH 5 - PROGRESS: at 13.68% examples, 111010 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:48: EPOCH 5 - PROGRESS: at 31.64% examples, 115204 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:49: EPOCH 5 - PROGRESS: at 48.16% examples, 118723 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:50: EPOCH 5 - PROGRESS: at 63.54% examples, 116197 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:51: EPOCH 5 - PROGRESS: at 78.07% examples, 112899 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:52: EPOCH 5 - PROGRESS: at 94.60% examples, 113379 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:15:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:15:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:15:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:15:52: EPOCH - 5 : training on 1099932 raw words (749354 effective words) took 6.6s, 113779 effective words/s\n",
      "INFO - 00:15:52: training on a 5499660 raw words (3746064 effective words) took 32.9s, 114022 effective words/s\n",
      "INFO - 00:15:52: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:15:52: collecting all words and their counts\n",
      "INFO - 00:15:52: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:15:53: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:15:54: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:15:55: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:15:55: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:15:56: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:15:56: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:15:56: Loading a fresh vocabulary\n",
      "INFO - 00:15:56: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:15:56: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:15:56: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:15:56: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:15:56: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:15:57: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:15:57: resetting layer weights\n",
      "INFO - 00:16:03: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=3\n",
      "INFO - 00:16:04: EPOCH 1 - PROGRESS: at 12.88% examples, 103834 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:05: EPOCH 1 - PROGRESS: at 30.72% examples, 113486 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:06: EPOCH 1 - PROGRESS: at 46.07% examples, 115329 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:07: EPOCH 1 - PROGRESS: at 62.67% examples, 115435 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:08: EPOCH 1 - PROGRESS: at 81.71% examples, 117034 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:09: EPOCH 1 - PROGRESS: at 96.69% examples, 115988 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:09: EPOCH - 1 : training on 1099932 raw words (749555 effective words) took 6.4s, 116489 effective words/s\n",
      "INFO - 00:16:10: EPOCH 2 - PROGRESS: at 13.68% examples, 114060 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:16:11: EPOCH 2 - PROGRESS: at 29.88% examples, 114284 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:12: EPOCH 2 - PROGRESS: at 43.78% examples, 111375 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:13: EPOCH 2 - PROGRESS: at 60.80% examples, 113931 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:14: EPOCH 2 - PROGRESS: at 77.09% examples, 114071 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:16:15: EPOCH 2 - PROGRESS: at 92.94% examples, 113494 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:16: EPOCH - 2 : training on 1099932 raw words (749361 effective words) took 6.6s, 113739 effective words/s\n",
      "INFO - 00:16:17: EPOCH 3 - PROGRESS: at 12.88% examples, 105275 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:18: EPOCH 3 - PROGRESS: at 29.88% examples, 111699 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:19: EPOCH 3 - PROGRESS: at 42.19% examples, 104974 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:20: EPOCH 3 - PROGRESS: at 55.41% examples, 104064 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:21: EPOCH 3 - PROGRESS: at 72.66% examples, 107367 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:16:22: EPOCH 3 - PROGRESS: at 89.34% examples, 109034 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:23: EPOCH - 3 : training on 1099932 raw words (749271 effective words) took 6.7s, 111363 effective words/s\n",
      "INFO - 00:16:24: EPOCH 4 - PROGRESS: at 14.59% examples, 121419 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:25: EPOCH 4 - PROGRESS: at 32.44% examples, 121836 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:26: EPOCH 4 - PROGRESS: at 47.15% examples, 118365 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:27: EPOCH 4 - PROGRESS: at 62.67% examples, 116044 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:28: EPOCH 4 - PROGRESS: at 79.48% examples, 115878 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:29: EPOCH 4 - PROGRESS: at 95.64% examples, 115767 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:29: EPOCH - 4 : training on 1099932 raw words (749367 effective words) took 6.4s, 116847 effective words/s\n",
      "INFO - 00:16:30: EPOCH 5 - PROGRESS: at 12.09% examples, 101541 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:31: EPOCH 5 - PROGRESS: at 28.29% examples, 107632 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:32: EPOCH 5 - PROGRESS: at 42.19% examples, 106607 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:33: EPOCH 5 - PROGRESS: at 59.03% examples, 111696 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:34: EPOCH 5 - PROGRESS: at 77.09% examples, 115050 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:35: EPOCH 5 - PROGRESS: at 94.60% examples, 116986 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:16:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:35: EPOCH - 5 : training on 1099932 raw words (749472 effective words) took 6.4s, 117769 effective words/s\n",
      "INFO - 00:16:35: training on a 5499660 raw words (3747026 effective words) took 32.6s, 114987 effective words/s\n",
      "INFO - 00:16:35: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:16:36: collecting all words and their counts\n",
      "INFO - 00:16:36: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:16:36: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:16:37: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:16:38: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:16:39: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:16:40: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:16:40: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:16:40: Loading a fresh vocabulary\n",
      "INFO - 00:16:40: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:16:40: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:16:40: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:16:40: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:16:40: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:16:40: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:16:40: resetting layer weights\n",
      "INFO - 00:16:47: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4\n",
      "INFO - 00:16:48: EPOCH 1 - PROGRESS: at 11.29% examples, 93692 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:49: EPOCH 1 - PROGRESS: at 28.29% examples, 104406 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:50: EPOCH 1 - PROGRESS: at 43.78% examples, 108822 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:51: EPOCH 1 - PROGRESS: at 59.03% examples, 110234 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:52: EPOCH 1 - PROGRESS: at 77.09% examples, 112252 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:53: EPOCH 1 - PROGRESS: at 90.98% examples, 110419 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:16:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:16:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:16:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:16:53: EPOCH - 1 : training on 1099932 raw words (749440 effective words) took 6.7s, 111052 effective words/s\n",
      "INFO - 00:16:54: EPOCH 2 - PROGRESS: at 13.68% examples, 116552 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:55: EPOCH 2 - PROGRESS: at 29.08% examples, 109322 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:56: EPOCH 2 - PROGRESS: at 45.26% examples, 113397 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:58: EPOCH 2 - PROGRESS: at 62.67% examples, 115975 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:16:59: EPOCH 2 - PROGRESS: at 80.86% examples, 116716 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:00: EPOCH 2 - PROGRESS: at 96.69% examples, 116841 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:00: EPOCH - 2 : training on 1099932 raw words (749034 effective words) took 6.4s, 116771 effective words/s\n",
      "INFO - 00:17:01: EPOCH 3 - PROGRESS: at 12.88% examples, 103853 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:02: EPOCH 3 - PROGRESS: at 28.29% examples, 105481 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:03: EPOCH 3 - PROGRESS: at 44.53% examples, 111377 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:04: EPOCH 3 - PROGRESS: at 59.89% examples, 111543 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:05: EPOCH 3 - PROGRESS: at 77.09% examples, 112616 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:06: EPOCH 3 - PROGRESS: at 95.64% examples, 115447 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:06: EPOCH - 3 : training on 1099932 raw words (748947 effective words) took 6.4s, 116416 effective words/s\n",
      "INFO - 00:17:07: EPOCH 4 - PROGRESS: at 13.68% examples, 113322 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:08: EPOCH 4 - PROGRESS: at 29.08% examples, 108110 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:09: EPOCH 4 - PROGRESS: at 45.26% examples, 113773 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:10: EPOCH 4 - PROGRESS: at 62.67% examples, 116210 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:11: EPOCH 4 - PROGRESS: at 81.71% examples, 118263 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:12: EPOCH 4 - PROGRESS: at 96.69% examples, 117669 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:13: EPOCH - 4 : training on 1099932 raw words (749268 effective words) took 6.3s, 118424 effective words/s\n",
      "INFO - 00:17:14: EPOCH 5 - PROGRESS: at 14.59% examples, 121699 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:15: EPOCH 5 - PROGRESS: at 32.44% examples, 123048 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:16: EPOCH 5 - PROGRESS: at 47.15% examples, 120194 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:17: EPOCH 5 - PROGRESS: at 64.46% examples, 121028 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:18: EPOCH 5 - PROGRESS: at 82.48% examples, 120401 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:19: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:17:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:19: EPOCH 5 - PROGRESS: at 100.00% examples, 121729 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:17:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:19: EPOCH - 5 : training on 1099932 raw words (749375 effective words) took 6.2s, 121700 effective words/s\n",
      "INFO - 00:17:19: training on a 5499660 raw words (3746064 effective words) took 32.1s, 116596 effective words/s\n",
      "INFO - 00:17:19: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:17:19: collecting all words and their counts\n",
      "INFO - 00:17:19: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:17:20: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:17:21: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:17:22: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:17:22: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:17:23: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:17:23: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:17:23: Loading a fresh vocabulary\n",
      "INFO - 00:17:23: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:17:23: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:17:23: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:17:23: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:17:23: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:17:23: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:17:23: resetting layer weights\n",
      "INFO - 00:17:29: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=5\n",
      "INFO - 00:17:30: EPOCH 1 - PROGRESS: at 13.68% examples, 112404 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:31: EPOCH 1 - PROGRESS: at 30.72% examples, 116467 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:32: EPOCH 1 - PROGRESS: at 47.15% examples, 118028 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:34: EPOCH 1 - PROGRESS: at 61.71% examples, 115412 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:35: EPOCH 1 - PROGRESS: at 79.48% examples, 115804 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:36: EPOCH 1 - PROGRESS: at 96.69% examples, 117366 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:36: EPOCH - 1 : training on 1099932 raw words (749135 effective words) took 6.3s, 118562 effective words/s\n",
      "INFO - 00:17:37: EPOCH 2 - PROGRESS: at 14.59% examples, 122256 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:38: EPOCH 2 - PROGRESS: at 32.44% examples, 123333 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:39: EPOCH 2 - PROGRESS: at 49.26% examples, 124626 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:40: EPOCH 2 - PROGRESS: at 61.71% examples, 116559 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:41: EPOCH 2 - PROGRESS: at 77.09% examples, 114403 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:42: EPOCH 2 - PROGRESS: at 94.60% examples, 116129 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:42: EPOCH - 2 : training on 1099932 raw words (748800 effective words) took 6.4s, 117181 effective words/s\n",
      "INFO - 00:17:43: EPOCH 3 - PROGRESS: at 12.88% examples, 109772 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:44: EPOCH 3 - PROGRESS: at 28.29% examples, 107233 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:17:45: EPOCH 3 - PROGRESS: at 40.63% examples, 103035 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:46: EPOCH 3 - PROGRESS: at 54.41% examples, 103474 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:47: EPOCH 3 - PROGRESS: at 68.31% examples, 102891 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:48: EPOCH 3 - PROGRESS: at 84.14% examples, 103671 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:49: EPOCH 3 - PROGRESS: at 99.11% examples, 104139 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 00:17:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:49: EPOCH - 3 : training on 1099932 raw words (749456 effective words) took 7.2s, 104269 effective words/s\n",
      "INFO - 00:17:50: EPOCH 4 - PROGRESS: at 11.29% examples, 91360 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:51: EPOCH 4 - PROGRESS: at 26.72% examples, 97202 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:52: EPOCH 4 - PROGRESS: at 39.79% examples, 98489 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:53: EPOCH 4 - PROGRESS: at 51.93% examples, 97459 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:54: EPOCH 4 - PROGRESS: at 66.47% examples, 98422 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:56: EPOCH 4 - PROGRESS: at 80.86% examples, 97531 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:57: EPOCH 4 - PROGRESS: at 96.69% examples, 100617 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:17:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:17:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:17:57: EPOCH - 4 : training on 1099932 raw words (749169 effective words) took 7.4s, 100982 effective words/s\n",
      "INFO - 00:17:58: EPOCH 5 - PROGRESS: at 12.09% examples, 96695 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:17:59: EPOCH 5 - PROGRESS: at 29.08% examples, 106291 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:00: EPOCH 5 - PROGRESS: at 44.53% examples, 108686 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:01: EPOCH 5 - PROGRESS: at 59.03% examples, 107103 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:02: EPOCH 5 - PROGRESS: at 71.59% examples, 102893 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:03: EPOCH 5 - PROGRESS: at 88.45% examples, 105763 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:04: EPOCH - 5 : training on 1099932 raw words (748780 effective words) took 7.0s, 107372 effective words/s\n",
      "INFO - 00:18:04: training on a 5499660 raw words (3745340 effective words) took 34.3s, 109070 effective words/s\n",
      "INFO - 00:18:04: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:18:04: collecting all words and their counts\n",
      "INFO - 00:18:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:18:05: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:18:06: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:18:06: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:18:07: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:18:08: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:18:08: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:18:08: Loading a fresh vocabulary\n",
      "INFO - 00:18:08: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:18:08: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:18:08: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:18:08: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:18:08: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:18:08: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:18:08: resetting layer weights\n",
      "INFO - 00:18:15: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=6\n",
      "INFO - 00:18:16: EPOCH 1 - PROGRESS: at 11.29% examples, 91755 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:17: EPOCH 1 - PROGRESS: at 28.29% examples, 105464 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:18:18: EPOCH 1 - PROGRESS: at 42.19% examples, 106024 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:19: EPOCH 1 - PROGRESS: at 57.44% examples, 106489 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:20: EPOCH 1 - PROGRESS: at 70.25% examples, 103471 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:21: EPOCH 1 - PROGRESS: at 87.49% examples, 106164 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:22: EPOCH - 1 : training on 1099932 raw words (749384 effective words) took 6.9s, 108808 effective words/s\n",
      "INFO - 00:18:23: EPOCH 2 - PROGRESS: at 13.68% examples, 115102 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:24: EPOCH 2 - PROGRESS: at 29.88% examples, 115142 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:25: EPOCH 2 - PROGRESS: at 45.26% examples, 116172 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:26: EPOCH 2 - PROGRESS: at 61.71% examples, 116481 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:27: EPOCH 2 - PROGRESS: at 79.48% examples, 116272 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:18:28: EPOCH 2 - PROGRESS: at 94.60% examples, 116118 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:18:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:28: EPOCH - 2 : training on 1099932 raw words (749450 effective words) took 6.4s, 116639 effective words/s\n",
      "INFO - 00:18:29: EPOCH 3 - PROGRESS: at 12.88% examples, 105333 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:30: EPOCH 3 - PROGRESS: at 30.72% examples, 112724 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:31: EPOCH 3 - PROGRESS: at 47.15% examples, 115914 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:32: EPOCH 3 - PROGRESS: at 61.71% examples, 114035 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:33: EPOCH 3 - PROGRESS: at 79.48% examples, 114964 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:34: EPOCH 3 - PROGRESS: at 92.94% examples, 112881 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:35: EPOCH - 3 : training on 1099932 raw words (749598 effective words) took 6.6s, 114243 effective words/s\n",
      "INFO - 00:18:36: EPOCH 4 - PROGRESS: at 13.68% examples, 115769 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:37: EPOCH 4 - PROGRESS: at 31.64% examples, 120140 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:18:38: EPOCH 4 - PROGRESS: at 48.16% examples, 120126 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:39: EPOCH 4 - PROGRESS: at 64.46% examples, 120161 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:40: EPOCH 4 - PROGRESS: at 82.48% examples, 120299 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:41: EPOCH 4 - PROGRESS: at 97.94% examples, 119422 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 00:18:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:41: EPOCH - 4 : training on 1099932 raw words (749759 effective words) took 6.2s, 120337 effective words/s\n",
      "INFO - 00:18:42: EPOCH 5 - PROGRESS: at 12.88% examples, 108600 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:43: EPOCH 5 - PROGRESS: at 29.88% examples, 112311 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:44: EPOCH 5 - PROGRESS: at 44.53% examples, 112793 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:18:45: EPOCH 5 - PROGRESS: at 59.03% examples, 111260 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:46: EPOCH 5 - PROGRESS: at 73.50% examples, 108452 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:47: EPOCH 5 - PROGRESS: at 87.49% examples, 107286 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:18:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:18:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:18:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:18:48: EPOCH - 5 : training on 1099932 raw words (749280 effective words) took 7.0s, 107337 effective words/s\n",
      "INFO - 00:18:48: training on a 5499660 raw words (3747471 effective words) took 33.1s, 113099 effective words/s\n",
      "INFO - 00:18:48: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:18:48: collecting all words and their counts\n",
      "INFO - 00:18:48: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:18:49: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:18:50: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:18:51: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:18:52: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:18:52: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:18:52: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:18:52: Loading a fresh vocabulary\n",
      "INFO - 00:18:52: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:18:52: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:18:53: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:18:53: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:18:53: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:18:53: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:18:53: resetting layer weights\n",
      "INFO - 00:19:00: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=7\n",
      "INFO - 00:19:01: EPOCH 1 - PROGRESS: at 10.44% examples, 84976 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:02: EPOCH 1 - PROGRESS: at 27.51% examples, 100409 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:03: EPOCH 1 - PROGRESS: at 42.96% examples, 106937 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:04: EPOCH 1 - PROGRESS: at 58.21% examples, 108528 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:05: EPOCH 1 - PROGRESS: at 75.18% examples, 111066 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:06: EPOCH 1 - PROGRESS: at 91.94% examples, 111772 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:19:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:07: EPOCH - 1 : training on 1099932 raw words (749251 effective words) took 6.7s, 112255 effective words/s\n",
      "INFO - 00:19:08: EPOCH 2 - PROGRESS: at 12.09% examples, 99478 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:09: EPOCH 2 - PROGRESS: at 28.29% examples, 103196 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:10: EPOCH 2 - PROGRESS: at 40.63% examples, 99466 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:11: EPOCH 2 - PROGRESS: at 53.64% examples, 98298 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:12: EPOCH 2 - PROGRESS: at 68.31% examples, 98727 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:13: EPOCH 2 - PROGRESS: at 84.14% examples, 99822 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:14: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:19:14: EPOCH 2 - PROGRESS: at 100.00% examples, 101542 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:19:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:14: EPOCH - 2 : training on 1099932 raw words (748969 effective words) took 7.4s, 101523 effective words/s\n",
      "INFO - 00:19:15: EPOCH 3 - PROGRESS: at 14.59% examples, 119437 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:16: EPOCH 3 - PROGRESS: at 32.44% examples, 122039 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:17: EPOCH 3 - PROGRESS: at 46.07% examples, 116082 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:18: EPOCH 3 - PROGRESS: at 60.80% examples, 114078 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:19: EPOCH 3 - PROGRESS: at 76.24% examples, 112640 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:20: EPOCH 3 - PROGRESS: at 91.94% examples, 112384 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:19:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:21: EPOCH - 3 : training on 1099932 raw words (749455 effective words) took 6.7s, 112069 effective words/s\n",
      "INFO - 00:19:22: EPOCH 4 - PROGRESS: at 12.09% examples, 98509 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:23: EPOCH 4 - PROGRESS: at 27.51% examples, 102416 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:24: EPOCH 4 - PROGRESS: at 41.41% examples, 103414 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:25: EPOCH 4 - PROGRESS: at 57.44% examples, 107325 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:26: EPOCH 4 - PROGRESS: at 74.28% examples, 110132 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:27: EPOCH 4 - PROGRESS: at 90.98% examples, 112067 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:19:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:27: EPOCH - 4 : training on 1099932 raw words (749164 effective words) took 6.6s, 113635 effective words/s\n",
      "INFO - 00:19:28: EPOCH 5 - PROGRESS: at 14.59% examples, 119375 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:29: EPOCH 5 - PROGRESS: at 32.44% examples, 121357 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:30: EPOCH 5 - PROGRESS: at 49.26% examples, 122465 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:31: EPOCH 5 - PROGRESS: at 66.47% examples, 123775 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:33: EPOCH 5 - PROGRESS: at 84.93% examples, 123631 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:19:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:33: EPOCH - 5 : training on 1099932 raw words (748769 effective words) took 6.0s, 124487 effective words/s\n",
      "INFO - 00:19:33: training on a 5499660 raw words (3745608 effective words) took 33.4s, 112165 effective words/s\n",
      "INFO - 00:19:33: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:19:34: collecting all words and their counts\n",
      "INFO - 00:19:34: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:19:34: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:19:35: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:19:36: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:19:37: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:19:37: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:19:37: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:19:37: Loading a fresh vocabulary\n",
      "INFO - 00:19:38: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:19:38: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:19:38: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:19:38: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:19:38: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:19:38: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:19:38: resetting layer weights\n",
      "INFO - 00:19:45: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=8\n",
      "INFO - 00:19:46: EPOCH 1 - PROGRESS: at 10.44% examples, 82798 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:47: EPOCH 1 - PROGRESS: at 25.60% examples, 93403 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:48: EPOCH 1 - PROGRESS: at 39.79% examples, 96256 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:49: EPOCH 1 - PROGRESS: at 54.41% examples, 98854 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:50: EPOCH 1 - PROGRESS: at 68.31% examples, 98188 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:51: EPOCH 1 - PROGRESS: at 83.31% examples, 98378 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:19:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:19:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:19:52: EPOCH - 1 : training on 1099932 raw words (749440 effective words) took 7.3s, 102179 effective words/s\n",
      "INFO - 00:19:53: EPOCH 2 - PROGRESS: at 12.88% examples, 110020 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:54: EPOCH 2 - PROGRESS: at 27.51% examples, 104876 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:55: EPOCH 2 - PROGRESS: at 38.94% examples, 99479 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:57: EPOCH 2 - PROGRESS: at 51.93% examples, 98928 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:19:58: EPOCH 2 - PROGRESS: at 67.56% examples, 101170 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:19:59: EPOCH 2 - PROGRESS: at 83.31% examples, 101942 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:00: EPOCH 2 - PROGRESS: at 100.00% examples, 104915 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:20:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:00: EPOCH - 2 : training on 1099932 raw words (749034 effective words) took 7.1s, 104891 effective words/s\n",
      "INFO - 00:20:01: EPOCH 3 - PROGRESS: at 13.68% examples, 111178 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:02: EPOCH 3 - PROGRESS: at 29.88% examples, 112002 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:03: EPOCH 3 - PROGRESS: at 46.07% examples, 115095 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:04: EPOCH 3 - PROGRESS: at 61.71% examples, 113520 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:05: EPOCH 3 - PROGRESS: at 75.18% examples, 110024 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:06: EPOCH 3 - PROGRESS: at 89.34% examples, 108215 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:07: EPOCH - 3 : training on 1099932 raw words (748945 effective words) took 6.9s, 108554 effective words/s\n",
      "INFO - 00:20:08: EPOCH 4 - PROGRESS: at 12.09% examples, 100093 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:09: EPOCH 4 - PROGRESS: at 26.72% examples, 97761 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:10: EPOCH 4 - PROGRESS: at 40.63% examples, 101435 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:11: EPOCH 4 - PROGRESS: at 53.64% examples, 100792 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:12: EPOCH 4 - PROGRESS: at 69.26% examples, 103227 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:13: EPOCH 4 - PROGRESS: at 86.59% examples, 106342 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:13: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:20:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:13: EPOCH - 4 : training on 1099932 raw words (749412 effective words) took 6.9s, 108704 effective words/s\n",
      "INFO - 00:20:14: EPOCH 5 - PROGRESS: at 12.88% examples, 107218 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:15: EPOCH 5 - PROGRESS: at 29.08% examples, 109962 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:17: EPOCH 5 - PROGRESS: at 44.53% examples, 112383 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:18: EPOCH 5 - PROGRESS: at 60.80% examples, 113896 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:19: EPOCH 5 - PROGRESS: at 75.18% examples, 111247 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:20: EPOCH 5 - PROGRESS: at 87.49% examples, 106795 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:20: EPOCH - 5 : training on 1099932 raw words (749233 effective words) took 7.0s, 106940 effective words/s\n",
      "INFO - 00:20:20: training on a 5499660 raw words (3746064 effective words) took 35.3s, 106044 effective words/s\n",
      "INFO - 00:20:20: precomputing L2-norms of word weight vectors\n",
      "INFO - 00:20:21: collecting all words and their counts\n",
      "INFO - 00:20:21: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:20:21: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 00:20:22: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 00:20:23: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 00:20:24: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 00:20:25: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 00:20:25: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 00:20:25: Loading a fresh vocabulary\n",
      "INFO - 00:20:25: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 00:20:25: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 00:20:25: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 00:20:25: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 00:20:25: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 00:20:25: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 00:20:25: resetting layer weights\n",
      "INFO - 00:20:32: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=9\n",
      "INFO - 00:20:33: EPOCH 1 - PROGRESS: at 12.09% examples, 99398 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:34: EPOCH 1 - PROGRESS: at 26.72% examples, 99546 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:35: EPOCH 1 - PROGRESS: at 41.41% examples, 104819 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:36: EPOCH 1 - PROGRESS: at 54.41% examples, 102806 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:37: EPOCH 1 - PROGRESS: at 68.31% examples, 102091 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:20:38: EPOCH 1 - PROGRESS: at 82.48% examples, 100312 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:39: EPOCH 1 - PROGRESS: at 97.79% examples, 101676 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:39: EPOCH - 1 : training on 1099932 raw words (748862 effective words) took 7.3s, 102033 effective words/s\n",
      "INFO - 00:20:40: EPOCH 2 - PROGRESS: at 12.88% examples, 107774 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:41: EPOCH 2 - PROGRESS: at 29.08% examples, 110574 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:42: EPOCH 2 - PROGRESS: at 42.96% examples, 109356 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:43: EPOCH 2 - PROGRESS: at 59.03% examples, 111258 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:44: EPOCH 2 - PROGRESS: at 77.09% examples, 113659 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:45: EPOCH 2 - PROGRESS: at 92.94% examples, 112808 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:46: EPOCH - 2 : training on 1099932 raw words (749609 effective words) took 6.7s, 112177 effective words/s\n",
      "INFO - 00:20:47: EPOCH 3 - PROGRESS: at 12.09% examples, 102258 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:48: EPOCH 3 - PROGRESS: at 28.29% examples, 107912 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:49: EPOCH 3 - PROGRESS: at 42.19% examples, 106174 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:50: EPOCH 3 - PROGRESS: at 58.21% examples, 109428 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:51: EPOCH 3 - PROGRESS: at 75.18% examples, 111004 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:20:52: EPOCH 3 - PROGRESS: at 91.94% examples, 112109 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:52: EPOCH - 3 : training on 1099932 raw words (749319 effective words) took 6.6s, 112684 effective words/s\n",
      "INFO - 00:20:54: EPOCH 4 - PROGRESS: at 12.09% examples, 96909 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:55: EPOCH 4 - PROGRESS: at 27.51% examples, 100066 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:56: EPOCH 4 - PROGRESS: at 42.96% examples, 105307 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:57: EPOCH 4 - PROGRESS: at 56.48% examples, 103572 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:58: EPOCH 4 - PROGRESS: at 71.59% examples, 103993 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:20:59: EPOCH 4 - PROGRESS: at 89.34% examples, 107364 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:20:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:59: EPOCH - 4 : training on 1099932 raw words (749166 effective words) took 6.9s, 109080 effective words/s\n",
      "INFO - 00:21:00: EPOCH 5 - PROGRESS: at 13.68% examples, 114848 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:21:01: EPOCH 5 - PROGRESS: at 31.64% examples, 119132 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:21:02: EPOCH 5 - PROGRESS: at 48.16% examples, 120696 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:21:03: EPOCH 5 - PROGRESS: at 64.46% examples, 120258 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:21:05: EPOCH 5 - PROGRESS: at 81.71% examples, 118349 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:21:06: EPOCH 5 - PROGRESS: at 96.69% examples, 117337 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:21:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:06: EPOCH - 5 : training on 1099932 raw words (749129 effective words) took 6.4s, 117356 effective words/s\n",
      "INFO - 00:21:06: training on a 5499660 raw words (3746085 effective words) took 34.0s, 110292 effective words/s\n",
      "INFO - 00:21:06: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Choix de la fenêtre, on aimerait que le modèle aprenne vite, on alongera ensuite le nombre d'epochs\n",
    "\n",
    "liste_modeles = [Word2Vec(\n",
    "                     window = i,\n",
    "                     size = 300,\n",
    "                     sample = 6e-5, \n",
    "                     alpha = 0.03, \n",
    "                     min_alpha = 0.0007, \n",
    "                     negative = 20,\n",
    "                     workers = cores - 1,\n",
    "                     compute_loss = True)\n",
    "                 \n",
    "                 for i in range(1, 10)\n",
    "                ]\n",
    "\n",
    "tests_fenetre = []\n",
    "\n",
    "for i in range(len(liste_modeles)):\n",
    "    \n",
    "    model = liste_modeles[i]\n",
    "    model.build_vocab(sentences_novice, progress_per = 10000)\n",
    "\n",
    "\n",
    "    model.train(sentences_novice, total_examples = model.corpus_count, epochs = 5, report_delay = 1)\n",
    "\n",
    "    tests_fenetre.append([\n",
    "            (model.wv.most_similar(positive=['droite'])[i][0],\n",
    "             model.wv.most_similar(positive=['vitesse'])[i][0],\n",
    "             model.wv.most_similar(positive=['donc'])[i][0],\n",
    "            )\n",
    "         for i in range(10)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('résolu', 'suivis', 'donne_avis'),\n",
       "  ('vécu', 'multiplient', 'adopté'),\n",
       "  ('assemblée_sénat', 'gratuitement', 'voter'),\n",
       "  ('représentés', 'conflit_intérêts', 'amendements'),\n",
       "  ('abouti', 'faire_croire', 'déposé'),\n",
       "  ('voter_texte', 'allégements', 'émets_donc'),\n",
       "  ('débouché', 'vingt_sept', 'sous_amendements'),\n",
       "  ('fait_unanimité', 'donnent', 'voilà_pourquoi'),\n",
       "  ('france_comores', 'instaurée', 'gouvernement'),\n",
       "  ('accord_trouvé', 'réclament', 'adopter')],\n",
       " [('pouvions', 'saurait_être', 'conséquent'),\n",
       "  ('dépassé', 'reconstruction', 'article'),\n",
       "  ('gauche', 'multiplient', 'donne_avis'),\n",
       "  ('avril', 'rendra', 'voter'),\n",
       "  ('vécu', 'bonne_nouvelle', 'rédaction'),\n",
       "  ('résolu', 'confort', 'adopté'),\n",
       "  ('représentés', 'regroupement', 'donc_satisfait'),\n",
       "  ('faisait', 'cherché', 'texte'),\n",
       "  ('attend', 'ajoutent', 'déposé'),\n",
       "  ('référendum', 'continueront', 'adopter')],\n",
       " [('gauche', 'plus_élevés', 'sous_amendements'),\n",
       "  ('pouvions', 'rendra', 'donne_avis'),\n",
       "  ('résolu', 'massivement', 'rédaction'),\n",
       "  ('parvenus', 'exportation', 'raison_laquelle'),\n",
       "  ('seuls_contre', 'augmentant', 'demande_retirer'),\n",
       "  ('avril', 'réclament', 'raisons'),\n",
       "  ('voter_texte', 'utilisée', 'donc_satisfait'),\n",
       "  ('préféré', 'distinction_entre', 'alinéa'),\n",
       "  ('abouti', 'existant', 'adopté'),\n",
       "  ('vécu', 'analyser', 'émettrais_avis')],\n",
       " [('gauche', 'continueront', 'invite_retirer'),\n",
       "  ('allait', 'exportation', 'donne_avis'),\n",
       "  ('seuls_contre', 'massivement', 'conséquent'),\n",
       "  ('a_su', 'plus_forte', 'sinon_avis'),\n",
       "  ('tiens_souligner', 'situation_actuelle', 'demande_retirer'),\n",
       "  ('avril', 'longues', 'faute_quoi'),\n",
       "  ('tribune', 'reconstruction', 'donnerai_avis'),\n",
       "  ('connaissez_bien', 'accélération', 'émets_donc'),\n",
       "  ('fermement', 'impossibilité', 'raisons'),\n",
       "  ('quel_point', 'condamner', 'donc_satisfait')],\n",
       " [('accompli', 'réclament', 'semble_donc'),\n",
       "  ('confirmer', 'détruire', 'demande'),\n",
       "  ('saluer_travail', 'reconstruction', 'pense'),\n",
       "  ('gauche', 'suivis', 'objet'),\n",
       "  ('collègues_sénateurs', 'peuvent_avoir', 'puisqu'),\n",
       "  ('quelques_jours', 'vins', 'sens'),\n",
       "  ('majorité', 'messages', 'donne'),\n",
       "  ('a_souhaité', 'massivement', 'contenu'),\n",
       "  ('vôtre', 'dizaine', 'disposition'),\n",
       "  ('entendue', 'certaines_conditions', 'supprimer')],\n",
       " [('gauche', 'navires', 'propose_donc'),\n",
       "  ('seuls_contre', 'vins', 'retirer'),\n",
       "  ('allait', 'transformé', 'semble'),\n",
       "  ('beaucoup_choses', 'grande_majorité', 'conseil_état'),\n",
       "  ('disait', 'deviendra', 'faute_quoi'),\n",
       "  ('débat_parlementaire', 'électriques', 'objet'),\n",
       "  ('pouvions', 'longues', 'émettrais_avis'),\n",
       "  ('eh_bien', 'urbain', 'défaut_quoi'),\n",
       "  ('ferons', 'intermédiaires', 'conséquent'),\n",
       "  ('socialistes', 'exploitations', 'donc_satisfait')],\n",
       " [('gauche', 'électriques', 'paraît'),\n",
       "  ('confirmer', 'exploitations', 'défaut'),\n",
       "  ('députée', 'multiplient', 'relève'),\n",
       "  ('bruno_maire', 'images', 'sens'),\n",
       "  ('députés_majorité', 'navires', 'semble_donc'),\n",
       "  ('lr', 'repas', 'mention'),\n",
       "  ('sincèrement', 'faiblesse', 'modification'),\n",
       "  ('quelques_mots', 'jusqu_alors', 'puisqu'),\n",
       "  ('banc', 'titre_exemple', 'code_civil'),\n",
       "  ('sein_groupe', 'incluant', 'tend')],\n",
       " [('habitude', 'images', 'paraît'),\n",
       "  ('soutenu', 'utilisée', 'défaut'),\n",
       "  ('seuls_contre', 'humains', 'semble_donc'),\n",
       "  ('gauche', 'paysans', 'supprimer'),\n",
       "  ('députés_majorité', 'électriques', 'relève'),\n",
       "  ('quel_point', 'incluant', 'puisque'),\n",
       "  ('oppositions', 'importation', 'décret'),\n",
       "  ('socialistes', 'exploitations', 'définition'),\n",
       "  ('maintenant', 'rendant', 'contenu'),\n",
       "  ('débat_parlementaire', 'reconstruction', 'modifier')],\n",
       " [('socialistes', 'électriques', 'tel'),\n",
       "  ('ici', 'bornes', 'prévoir'),\n",
       "  ('débat_parlementaire', 'engie', 'défaut'),\n",
       "  ('habitude', 'titre_exemple', 'juridique'),\n",
       "  ('sincèrement', 'généralisé', 'sanction'),\n",
       "  ('discours', 'électronique', 'pense'),\n",
       "  ('gauche', 'images', 'celui_ci'),\n",
       "  ('députés_majorité', 'utilise', 'définition'),\n",
       "  ('veux_saluer', 'navires', 'supprimer'),\n",
       "  ('pu', 'favorisera', 'sanctions')]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_fenetre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit window = 4 qualitativement (on se restreint d'abord aux modèles qui associent en premier 'gauche' à 'droite', puis on sélectionne sur la pertinence des autres mots sélectionnés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 01:04:04: collecting all words and their counts\n",
      "INFO - 01:04:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 01:04:05: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 01:04:06: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 01:04:07: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 01:04:08: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 01:04:09: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 01:04:09: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 01:04:09: Loading a fresh vocabulary\n",
      "INFO - 01:04:09: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 01:04:09: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 01:04:09: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 01:04:09: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 01:04:09: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 01:04:09: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 01:04:09: resetting layer weights\n",
      "INFO - 01:04:17: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4\n",
      "INFO - 01:04:18: EPOCH 1 - PROGRESS: at 13.68% examples, 111634 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:19: EPOCH 1 - PROGRESS: at 30.72% examples, 114519 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:20: EPOCH 1 - PROGRESS: at 43.78% examples, 110229 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:21: EPOCH 1 - PROGRESS: at 59.89% examples, 111260 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:22: EPOCH 1 - PROGRESS: at 75.18% examples, 109527 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:23: EPOCH 1 - PROGRESS: at 90.20% examples, 108835 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 01:04:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 01:04:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 01:04:24: EPOCH - 1 : training on 1099932 raw words (749480 effective words) took 6.9s, 107934 effective words/s\n",
      "INFO - 01:04:25: EPOCH 2 - PROGRESS: at 11.29% examples, 93867 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 01:04:26: EPOCH 2 - PROGRESS: at 24.42% examples, 91698 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 01:04:27: EPOCH 2 - PROGRESS: at 35.26% examples, 86780 words/s, in_qsize 0, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "# Maintenant qu'on a la fenêtre, on fait le choix du nombre d'époques lors de l'apprentissage. \n",
    "# On reprend le même procédé pour tester la fiabilité\n",
    "\n",
    "tests_epochs = []\n",
    "\n",
    "liste_nb_epochs = [250]\n",
    "\n",
    "for nb_epochs in liste_nb_epochs:\n",
    "    \n",
    "    model = Word2Vec(\n",
    "                     window = 4,\n",
    "                     size = 300,\n",
    "                     sample = 6e-5, \n",
    "                     alpha = 0.03, \n",
    "                     min_alpha = 0.0007, \n",
    "                     negative = 20,\n",
    "                     workers = cores - 1,\n",
    "                     compute_loss = True)\n",
    "    \n",
    "    model.build_vocab(sentences_novice, progress_per = 10000)\n",
    "\n",
    "    model.train(sentences_novice, total_examples = model.corpus_count, epochs = nb_epochs, report_delay = 1)\n",
    "\n",
    "    tests_epochs.append([\n",
    "            (model.wv.most_similar(positive=['droite'])[i][0],\n",
    "             model.wv.most_similar(positive=['vitesse'])[i][0],\n",
    "             model.wv.most_similar(positive=['donc'])[i][0],\n",
    "            )\n",
    "         for i in range(10)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_novice = Word2Vec(\n",
    "                     window = 1,\n",
    "                     size = 300,\n",
    "                     sample = 6e-5, \n",
    "                     alpha = 0.03, \n",
    "                     min_alpha = 0.0007, \n",
    "                     negative = 20,\n",
    "                     workers = cores - 1,\n",
    "                     compute_loss = True)\n",
    "\n",
    "w2v_model_exp = Word2Vec(\n",
    "                     window = 4,\n",
    "                     size = 300,\n",
    "                     sample = 6e-5, \n",
    "                     alpha = 0.03, \n",
    "                     min_alpha = 0.0007, \n",
    "                     negative = 20,\n",
    "                     workers = cores - 1,\n",
    "                     compute_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:19: collecting all words and their counts\n",
      "INFO - 21:28:19: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 21:28:19: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 21:28:20: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 21:28:21: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 21:28:22: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 21:28:22: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 21:28:22: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 21:28:22: Loading a fresh vocabulary\n",
      "INFO - 21:28:22: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 21:28:22: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 21:28:23: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 21:28:23: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 21:28:23: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 21:28:23: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 21:28:23: resetting layer weights\n",
      "INFO - 21:28:29: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.18 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:30: EPOCH 1 - PROGRESS: at 14.59% examples, 119085 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 21:28:31: EPOCH 1 - PROGRESS: at 29.88% examples, 113220 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:32: EPOCH 1 - PROGRESS: at 41.41% examples, 104014 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:33: EPOCH 1 - PROGRESS: at 55.41% examples, 104272 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:34: EPOCH 1 - PROGRESS: at 70.25% examples, 104299 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:35: EPOCH 1 - PROGRESS: at 85.67% examples, 104728 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:28:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:28:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:28:36: EPOCH - 1 : training on 1099932 raw words (749232 effective words) took 6.9s, 108082 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:37: EPOCH 2 - PROGRESS: at 14.59% examples, 123502 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:28:38: EPOCH 2 - PROGRESS: at 32.44% examples, 125605 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:39: EPOCH 2 - PROGRESS: at 50.17% examples, 128152 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:40: EPOCH 2 - PROGRESS: at 66.47% examples, 126086 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:41: EPOCH 2 - PROGRESS: at 82.48% examples, 121550 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:42: EPOCH 2 - PROGRESS: at 97.94% examples, 120822 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 21:28:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:28:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:28:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:28:42: EPOCH - 2 : training on 1099932 raw words (749796 effective words) took 6.2s, 121716 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:43: EPOCH 3 - PROGRESS: at 13.68% examples, 114145 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:44: EPOCH 3 - PROGRESS: at 31.64% examples, 120600 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:45: EPOCH 3 - PROGRESS: at 45.26% examples, 115764 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:46: EPOCH 3 - PROGRESS: at 60.80% examples, 114749 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:47: EPOCH 3 - PROGRESS: at 78.07% examples, 116350 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:28:48: EPOCH 3 - PROGRESS: at 92.94% examples, 114964 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:28:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:28:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:28:49: EPOCH - 3 : training on 1099932 raw words (749338 effective words) took 6.6s, 113274 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 2: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:50: EPOCH 4 - PROGRESS: at 11.29% examples, 88611 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:51: EPOCH 4 - PROGRESS: at 26.72% examples, 98172 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:52: EPOCH 4 - PROGRESS: at 42.19% examples, 105034 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:53: EPOCH 4 - PROGRESS: at 59.89% examples, 110851 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:54: EPOCH 4 - PROGRESS: at 76.24% examples, 111668 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:28:55: EPOCH 4 - PROGRESS: at 92.94% examples, 112536 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:28:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:28:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:28:56: EPOCH - 4 : training on 1099932 raw words (748841 effective words) took 6.6s, 113427 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:28:57: EPOCH 5 - PROGRESS: at 13.68% examples, 112279 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:58: EPOCH 5 - PROGRESS: at 31.64% examples, 117498 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:28:59: EPOCH 5 - PROGRESS: at 48.16% examples, 118506 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:00: EPOCH 5 - PROGRESS: at 64.46% examples, 118211 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:01: EPOCH 5 - PROGRESS: at 80.86% examples, 116209 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:02: EPOCH 5 - PROGRESS: at 97.79% examples, 117621 words/s, in_qsize 3, out_qsize 0\n",
      "INFO - 21:29:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:02: EPOCH - 5 : training on 1099932 raw words (749292 effective words) took 6.3s, 118681 effective words/s\n",
      "INFO - 21:29:02: training on a 5499660 raw words (3746499 effective words) took 32.7s, 114621 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 4: 0.0\n",
      "Time to train the model: 0.54 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model_novice.build_vocab(sentences_novice, progress_per = 10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "t = time()\n",
    "\n",
    "w2v_model_novice.train(sentences_novice, total_examples = w2v_model_novice.corpus_count, epochs = 5, report_delay = 1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:02: collecting all words and their counts\n",
      "INFO - 21:29:02: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 21:29:03: PROGRESS: at sentence #10000, processed 233965 words, keeping 30761 word types\n",
      "INFO - 21:29:04: PROGRESS: at sentence #20000, processed 450032 words, keeping 39850 word types\n",
      "INFO - 21:29:05: PROGRESS: at sentence #30000, processed 677772 words, keeping 48410 word types\n",
      "INFO - 21:29:05: PROGRESS: at sentence #40000, processed 880381 words, keeping 51772 word types\n",
      "INFO - 21:29:06: PROGRESS: at sentence #50000, processed 1095690 words, keeping 55266 word types\n",
      "INFO - 21:29:06: collected 55316 word types from a corpus of 1099932 raw words and 50191 sentences\n",
      "INFO - 21:29:06: Loading a fresh vocabulary\n",
      "INFO - 21:29:06: effective_min_count=5 retains 26248 unique words (47% of original 55316, drops 29068)\n",
      "INFO - 21:29:06: effective_min_count=5 leaves 1041812 word corpus (94% of original 1099932, drops 58120)\n",
      "INFO - 21:29:06: deleting the raw counts dictionary of 55316 items\n",
      "INFO - 21:29:06: sample=6e-05 downsamples 1069 most-common words\n",
      "INFO - 21:29:06: downsampling leaves estimated 749202 word corpus (71.9% of prior 1041812)\n",
      "INFO - 21:29:06: estimated required memory for 26248 words and 300 dimensions: 76119200 bytes\n",
      "INFO - 21:29:06: resetting layer weights\n",
      "INFO - 21:29:13: training model with 3 workers on 26248 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.19 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:14: EPOCH 1 - PROGRESS: at 8.94% examples, 75749 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:15: EPOCH 1 - PROGRESS: at 18.67% examples, 74386 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:16: EPOCH 1 - PROGRESS: at 29.08% examples, 72742 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:17: EPOCH 1 - PROGRESS: at 42.19% examples, 79422 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:18: EPOCH 1 - PROGRESS: at 55.41% examples, 82884 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:19: EPOCH 1 - PROGRESS: at 69.26% examples, 85337 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:20: EPOCH 1 - PROGRESS: at 83.31% examples, 86118 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:21: EPOCH 1 - PROGRESS: at 96.69% examples, 87870 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:22: EPOCH - 1 : training on 1099932 raw words (749440 effective words) took 8.5s, 88145 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:23: EPOCH 2 - PROGRESS: at 12.09% examples, 102900 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:24: EPOCH 2 - PROGRESS: at 28.29% examples, 108079 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:25: EPOCH 2 - PROGRESS: at 42.96% examples, 108831 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:26: EPOCH 2 - PROGRESS: at 57.44% examples, 108245 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:27: EPOCH 2 - PROGRESS: at 73.50% examples, 109556 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:28: EPOCH 2 - PROGRESS: at 89.34% examples, 110488 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:28: EPOCH - 2 : training on 1099932 raw words (749026 effective words) took 6.7s, 111941 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:29: EPOCH 3 - PROGRESS: at 13.68% examples, 116468 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:30: EPOCH 3 - PROGRESS: at 30.72% examples, 118834 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:31: EPOCH 3 - PROGRESS: at 45.26% examples, 116017 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:32: EPOCH 3 - PROGRESS: at 61.71% examples, 117252 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:33: EPOCH 3 - PROGRESS: at 76.24% examples, 112925 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:34: EPOCH 3 - PROGRESS: at 84.88% examples, 103613 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:35: EPOCH 3 - PROGRESS: at 97.79% examples, 102387 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:36: EPOCH - 3 : training on 1099932 raw words (749041 effective words) took 7.4s, 100947 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 2: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:37: EPOCH 4 - PROGRESS: at 12.09% examples, 96841 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:38: EPOCH 4 - PROGRESS: at 28.29% examples, 104410 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:39: EPOCH 4 - PROGRESS: at 42.96% examples, 107451 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:40: EPOCH 4 - PROGRESS: at 58.21% examples, 109042 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:41: EPOCH 4 - PROGRESS: at 74.28% examples, 110096 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:42: EPOCH 4 - PROGRESS: at 89.34% examples, 109838 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:43: EPOCH - 4 : training on 1099932 raw words (749485 effective words) took 7.0s, 107413 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 3: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:44: EPOCH 5 - PROGRESS: at 5.60% examples, 45192 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:45: EPOCH 5 - PROGRESS: at 18.67% examples, 72414 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:46: EPOCH 5 - PROGRESS: at 32.44% examples, 80824 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:47: EPOCH 5 - PROGRESS: at 49.26% examples, 91395 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:48: EPOCH 5 - PROGRESS: at 66.47% examples, 97581 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:49: EPOCH 5 - PROGRESS: at 84.93% examples, 102339 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:50: EPOCH - 5 : training on 1099932 raw words (749059 effective words) took 7.1s, 105619 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 4: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:51: EPOCH 6 - PROGRESS: at 13.68% examples, 107661 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 21:29:52: EPOCH 6 - PROGRESS: at 28.29% examples, 104059 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:53: EPOCH 6 - PROGRESS: at 43.78% examples, 109781 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:54: EPOCH 6 - PROGRESS: at 59.89% examples, 112487 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:55: EPOCH 6 - PROGRESS: at 77.09% examples, 114525 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:56: EPOCH 6 - PROGRESS: at 94.60% examples, 116083 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:29:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:29:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:29:56: EPOCH - 6 : training on 1099932 raw words (748910 effective words) took 6.4s, 117051 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 5: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:29:57: EPOCH 7 - PROGRESS: at 14.59% examples, 116907 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:29:58: EPOCH 7 - PROGRESS: at 32.44% examples, 121593 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:29:59: EPOCH 7 - PROGRESS: at 46.07% examples, 115467 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:00: EPOCH 7 - PROGRESS: at 61.71% examples, 115066 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:01: EPOCH 7 - PROGRESS: at 80.86% examples, 116855 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:02: EPOCH 7 - PROGRESS: at 97.79% examples, 118155 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:30:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:30:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:30:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:30:03: EPOCH - 7 : training on 1099932 raw words (749052 effective words) took 6.3s, 118804 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 6: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:30:04: EPOCH 8 - PROGRESS: at 14.59% examples, 115425 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 21:30:05: EPOCH 8 - PROGRESS: at 32.44% examples, 120776 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:06: EPOCH 8 - PROGRESS: at 47.15% examples, 117979 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:07: EPOCH 8 - PROGRESS: at 63.54% examples, 117762 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:30:08: EPOCH 8 - PROGRESS: at 79.48% examples, 114819 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:09: EPOCH 8 - PROGRESS: at 95.64% examples, 115588 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:30:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:30:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:30:09: EPOCH - 8 : training on 1099932 raw words (749594 effective words) took 6.4s, 116618 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 7: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:30:10: EPOCH 9 - PROGRESS: at 14.59% examples, 117248 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:11: EPOCH 9 - PROGRESS: at 32.44% examples, 120240 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:12: EPOCH 9 - PROGRESS: at 49.26% examples, 122064 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:13: EPOCH 9 - PROGRESS: at 65.34% examples, 121538 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:14: EPOCH 9 - PROGRESS: at 83.31% examples, 121394 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:15: EPOCH 9 - PROGRESS: at 97.79% examples, 118012 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:30:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:30:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:30:15: EPOCH - 9 : training on 1099932 raw words (749475 effective words) took 6.4s, 117322 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 8: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:30:16: EPOCH 10 - PROGRESS: at 13.68% examples, 116357 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:17: EPOCH 10 - PROGRESS: at 30.72% examples, 119219 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:30:18: EPOCH 10 - PROGRESS: at 47.15% examples, 121133 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 21:30:19: EPOCH 10 - PROGRESS: at 64.46% examples, 121811 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:20: EPOCH 10 - PROGRESS: at 83.31% examples, 122310 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 21:30:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:30:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:30:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:30:21: EPOCH - 10 : training on 1099932 raw words (749640 effective words) took 6.1s, 123889 effective words/s\n",
      "INFO - 21:30:21: training on a 10999320 raw words (7492722 effective words) took 68.4s, 109599 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 9: 0.0\n",
      "Time to train the model: 1.14 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model_exp.build_vocab(sentences_novice, progress_per = 10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "t = time()\n",
    "\n",
    "w2v_model_exp.train(sentences_novice, total_examples = w2v_model_exp.corpus_count, epochs = 10, report_delay = 1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 23:07:23: precomputing L2-norms of word weight vectors\n",
      "INFO - 23:07:23: precomputing L2-norms of word weight vectors\n",
      "INFO - 23:07:23: saving Word2Vec object under results/word2vec_novice.model, separately None\n",
      "INFO - 23:07:23: not storing attribute vectors_norm\n",
      "INFO - 23:07:23: not storing attribute cum_table\n",
      "INFO - 23:07:23: saved results/word2vec_novice.model\n",
      "INFO - 23:07:23: saving Word2Vec object under results/word2vec_exp.model, separately None\n",
      "INFO - 23:07:23: not storing attribute vectors_norm\n",
      "INFO - 23:07:23: not storing attribute cum_table\n",
      "INFO - 23:07:23: saved results/word2vec_exp.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model_novice.init_sims(replace = True)\n",
    "w2v_model_exp.init_sims(replace = True)\n",
    "\n",
    "w2v_model_novice.save(\"results/word2vec_novice_test.model\")\n",
    "w2v_model_exp.save(\"results/word2vec_exp_test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v_model.wv.most_similar(positive=[\"macron\"])\n",
    "#w2v_model.wv.most_similar(negative=[\"promesse\"])\n",
    "#w2v_model.wv.similarity(\"élection\", 'présidentielle')\n",
    "#w2v_model.wv.similarity(\"sport\", 'études')\n",
    "#print(w2v_model.wv.similarity(\"macron\", 'droite'))\n",
    "#print(w2v_model.wv.similarity(\"macron\", 'gauche'))\n",
    "#w2v_model.wv.doesnt_match(['gauche', 'président', 'droite'])\n",
    "#w2v_model.wv.most_similar(positive=[\"père\", \"femme\"], negative = ['homme'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gauche', 0.986516535282135),\n",
       " ('républicains', 0.9116498231887817),\n",
       " ('bancs', 0.9007534384727478),\n",
       " ('cet_hémicycle', 0.8813148736953735),\n",
       " ('hémicycle', 0.8689683675765991),\n",
       " ('france_insoumise', 0.8554179668426514),\n",
       " ('opposition', 0.8358474969863892),\n",
       " ('groupes', 0.802750825881958),\n",
       " ('voix', 0.800241231918335),\n",
       " ('groupe', 0.7991034984588623)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_novice.wv.most_similar(positive=[\"droite\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('droite_gauche', 0.6979137659072876),\n",
       " ('extrême_gauche', 0.6682906150817871),\n",
       " ('gauche', 0.6396193504333496),\n",
       " ('socialistes', 0.6157995462417603),\n",
       " ('majorité', 0.561996340751648),\n",
       " ('bancs', 0.5594807267189026),\n",
       " ('communistes', 0.5519882440567017),\n",
       " ('extrême_droite', 0.5514141321182251),\n",
       " ('rangs', 0.5431515574455261),\n",
       " ('oreille', 0.5347355008125305)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_exp.wv.most_similar(positive=[\"droite\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export_novice = pd.DataFrame(w2v_model_novice.wv.vectors)\n",
    "\n",
    "df_export_exp = pd.DataFrame(w2v_model_exp.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_novice = [w2v_model_novice.wv.most_similar(positive=[np.array(df_export_novice.iloc[i])])[0][0] for i in range(df_export_novice.shape[0])]\n",
    "\n",
    "words_exp = [w2v_model_exp.wv.most_similar(positive=[np.array(df_export_exp.iloc[i])])[0][0] for i in range(df_export_exp.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export_novice['word'] = words_novice\n",
    "\n",
    "df_export_exp['word'] = words_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export_novice.to_csv('results/embeddings_novice_test.csv')\n",
    "df_export_exp.to_csv('results/embeddings_exp_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
